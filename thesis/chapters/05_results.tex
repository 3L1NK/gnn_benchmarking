This chapter reports benchmark outcomes generated from \texttt{results/results\_tuned\_all.jsonl} through the hardened reporting pipeline. All tables and figures are synchronized from \texttt{results/reports/thesis\_tuned\_all/}. Every summary in this chapter is derived from the same canonical deduplicated dataframe (\texttt{master\_comparison.csv}) and checked against the canonical run matrix.

\section{Evaluation Context and Baselines}
The out-of-sample test window is January~2,~2020 to December~27,~2024. Baseline context is exported explicitly to avoid horizon mismatch between model equity and benchmark equity.
\input{tables/generated/baseline_context.tex}

The global buy-and-hold curve (from 2000 onward) is substantially higher than the rebased test-window curve by construction, so all comparative statements in this chapter use the test-window baseline only.

\section{Runtime and Compute Profile}
\input{tables/generated/runtime_summary.tex}

Runtime diagnostics show a strong family-level separation: graph models spend most wall time in training and graph-side preprocessing, while XGBoost variants train quickly and infer almost instantly. This is relevant for deployment engineering, where retraining cadence can dominate architecture choice.

\section{Visual Diagnostics by Rebalance Policy}

\subsection{Equity Trajectories}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{equity_curves_key_models_reb1.png}
  \caption{Equity curves for key model variants under daily rebalancing (\texttt{rebalance\_freq=1}).}
  \label{fig:equity-curves-reb1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{equity_curves_key_models_reb5.png}
  \caption{Equity curves for key model variants under weekly rebalancing (\texttt{rebalance\_freq=5}).}
  \label{fig:equity-curves-reb5}
\end{figure}

\subsection{Risk-Adjusted and Prediction Trade-Offs}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{ic_vs_sharpe_reb1.png}
  \caption{Rank IC versus annualized Sharpe for daily rebalancing.}
  \label{fig:ic-vs-sharpe-reb1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{ic_vs_sharpe_reb5.png}
  \caption{Rank IC versus annualized Sharpe for weekly rebalancing.}
  \label{fig:ic-vs-sharpe-reb5}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{risk_frontier_reb1.png}
  \caption{Risk frontier (annualized return versus max drawdown) for daily rebalancing.}
  \label{fig:risk-frontier-reb1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{risk_frontier_reb5.png}
  \caption{Risk frontier (annualized return versus max drawdown) for weekly rebalancing.}
  \label{fig:risk-frontier-reb5}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{bar_metrics_reb1.png}
  \caption{Top-model metric bars for daily rebalancing.}
  \label{fig:bar-metrics-reb1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{bar_metrics_reb5.png}
  \caption{Top-model metric bars for weekly rebalancing.}
  \label{fig:bar-metrics-reb5}
\end{figure}

\section{Main Comparison Tables}
\input{tables/generated/professor_main_results_table.tex}
\input{tables/generated/baseline_policy_comparison.tex}
\input{tables/generated/top_models_reb1.tex}
\input{tables/generated/top_models_reb5.tex}
\input{tables/generated/model_vs_baseline_reb1.tex}
\input{tables/generated/model_vs_baseline_reb5.tex}
\input{tables/generated/family_summary.tex}
\input{tables/generated/edge_ablation.tex}
\input{tables/generated/audit_status.tex}
\input{tables/generated/alpha_vs_equal_weight.tex}
\input{tables/generated/long_short_top3_bottom3.tex}
\input{tables/generated/cost_sensitivity_summary.tex}
\input{tables/generated/monthly_rebalance_subset.tex}
\input{tables/generated/lookback_sensitivity_subset.tex}

\section{Alpha and Market-Neutral Diagnostics}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{relative_wealth_key_models.png}
  \caption{Relative wealth of model portfolios vs Equal weight (rebalanced, all assets).}
  \label{fig:relative-wealth-vs-eqw}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{active_ir_vs_active_return.png}
  \caption{Active annualized return vs information ratio relative to Equal weight (rebalanced, all assets).}
  \label{fig:active-ir-vs-return}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{long_short_equity_top3_bottom3.png}
  \caption{Market-neutral long-short equity curves (top 3 long, bottom 3 short; gross).}
  \label{fig:long-short-top3-bottom3}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{cost_sensitivity_summary.png}
  \caption{Cost sensitivity summary under 0/5/10 bps.}
  \label{fig:cost-sensitivity-summary}
\end{figure}

\section{Primary Findings}
\textbf{1) Weekly rebalancing is systematically better in this benchmark.}
Across the canonical model variants, moving from daily to weekly rebalancing improves annualized Sharpe and reduces turnover for the majority of runs. This is consistent with lower implementation friction from less frequent trading.

\textbf{2) The top overall run is the graph-feature baseline.}
\texttt{xgb\_node2vec\_corr\_tuned\_all} is rank-1 under \texttt{rebalance\_freq=5}, with strong Sharpe and competitive drawdown. The result supports the claim that relational information is useful even when injected as features into a non-graph learner.

\textbf{3) Prediction metrics and portfolio metrics are related but not equivalent.}
RMSE/MAE spread is narrow relative to the spread in Rank IC and Sharpe. Several runs with similar point error produce materially different turnover and drawdown, showing why portfolio-aware evaluation is required.

\textbf{4) Family-level averages do not imply universal model dominance.}
XGBoost-family variants lead on mean Sharpe in this window, while GNNs remain competitive in selected edge settings. This supports a conditional conclusion: representation choice matters, but deployment utility depends on the full stack (edge design, rebalance policy, and costs).

\textbf{5) Edge ablation favors simpler sector priors over merged complexity on average.}
Sector-edge variants are strongest on mean GNN Sharpe in this tuned matrix. The combined \texttt{corr+sector+granger} graph does not dominate average outcomes, indicating that adding channels can introduce noise or instability.

\section{Buy-and-Hold Gap and Alpha Claims}
A critical result is that all tested model-driven strategies remain below test-window buy-and-hold final wealth in this period. Therefore, this thesis does \emph{not} make a broad alpha-superiority claim. The supported claim is narrower: under one controlled protocol, some graph-aware variants improve risk-adjusted portfolio diagnostics relative to other learned models, but they do not beat passive benchmark wealth in this regime.

\section{Research-Question Mapping}
\textbf{RQ1 (graph-based predictive quality):} partially supported. Graph-aware information helps, especially in graph-feature hybrids, but end-to-end GNNs are not uniformly dominant.

\textbf{RQ2 (useful edge signals):} sector edges are the most robust average GNN choice in this matrix.

\textbf{RQ3 (monetization of prediction gains):} partially supported. Improvements in ranking and Sharpe exist within model families, but absolute wealth remains below buy-and-hold in the 2020--2024 window.

\textbf{RQ4 (rebalance sensitivity):} strongly supported. Weekly rebalancing materially improves deployable quality by reducing turnover and often improving Sharpe.
